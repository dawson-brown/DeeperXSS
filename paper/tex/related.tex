Mokbal \textit{et al.} created a multilayer preceptron (MLP) model for detecting XSS both in dynamic webpages and URLs \cite{mokbal2019mlpxss}. Their approach, called MLPXSS, has three main pillars: data scraping, feature extraction, and an artificial neural network ANN. Their model is meant to deal with both dynamic webpages and malicious URLs. Their feature extraction level has 3 modules to extract HTML-based features, Javasript-based features, and URL-based features. The HTML module tokenizes tags, attributes and events--focusing on things that trigger Javascript execution (like \textit{href} or \textit{onclick}). The Javascript module parses and tokenizes Javascript code that is pulled from a webpage. There are various ways to include Javascript in a page like script tags, \textit{onclick} and \textit{onsubmit} calls, \textit{href}, etc... Lastly they tokenize potentially malicious parts of URLs, like HTML properties, tags, some keywords (\textit{login}, \textit{signup}), \textit{document} references, and various special characters like `$<$', `$>$' and `$/$'. The MLP is trained on token streams with a sigmoid output layer. Their perceptron had precision, f-measure, and accuracy all in excess of 99\% \cite{mokbal2019mlpxss}.

Zhang \textit{et al.} propose a dual Gaussian mixture model (GMM) approach that trains two seperate GMMs models (one for benign and one for malicious) and then combines their outputs to make a prediction. Additionaly, they train the models on both the URL and the server response to the URL in an attempt to get richer features \cite{zhang2019cross}. To preprocess the URLs, the decode, tokenize, and train a word2vec model to retrieve a vector representation of each token. Their tokenization approach is very similar to that of DeepXSS and MPLXSS, they however inclue the domain and path for the benign GMM. They are however generalized to simply `domain' and `path' \cite{zhang2019cross}. Their reasoning for this is that containing just a domain and path is characteristic of a benign URL, whereas an XSS URL is characterized by its maliciouly constructed parameters and not the presence of a domain and path \cite{zhang2019cross}. Their models can be trained on requests, responses, or both. They reason that in many cases, benign requests contain no XSS tokens, which isn't very interesting, however responses contain useful features for both XSS and none-XSS tokenization. Their multi-stage dual GMM using both responses and requests greatly improved classification \cite{zhang2019cross}.

Goswami \textit{et al.} propose a attribute clustering technique to perform unsupervised grouping of malicious and benign scripts. They're feature extraction is wholly different from DeepXSS and other deep learning classifiers. They propose 15 features that characterize malicious and benign scripts creating a 16-dimensional vector for each script (including class) \cite{goswami2017unsupervised}. These features are meta-features like length of the script, number of strings and the average string length, number of methods, number of unicode and hex characters, among others. These features are then min-max normalized before clustering \cite{goswami2017unsupervised}. Their algorithm was able to achieve an accuracy in excess of 98\% \cite{goswami2017unsupervised}.  