Fang \textit{et al.} claim to make 3 contributions in DeepXSS:

\begin{enumerate}
\item a decoder to undo URL obfuscation
\item a Word2Vec model to embed token strings
\item an LSTM classifier to detect XSS
\end{enumerate}

The decoder is a function that will recursively try to decode `all' possible URL encoding techniques \cite{fang2018deepxss}. Precisely what is meant by `all' encodings is unspecified nor is any source code provided. They however claim to be able to restore arbitrarily obfuscated data \cite{fang2018deepxss}.

After decoding, they `generalize' the resulting URLs. They map all domain names to simply `domain', all numbers to `1' and all string parameters to ``param\_string''. They also remove blank and control characters \cite{fang2018deepxss}. They give little justification for this and this step does not seem to affect feature extraction (tokenization) as parameters and numbers aren't tokenized (see table \ref{tok:tab}). 

The tokenization is the first step in feature extraction. They turn each URL into a sequence of tokens according to custom regexes. They do not provide those regexes, they merely provide a table summarizing the types of tokens being extracted (table \ref{tok:tab}) \cite{fang2018deepxss}. The tokens chosen appear to target only the types of strings that would be present in XSS payloads and many benign URLs contain no tokens. It appears that the classifier doesn't come to learn what benign URLs look like as the vast majority contain no features. 

\begin{table}
\begin{center}
\begingroup
\setlength{\tabcolsep}{5pt} % Default value: 6pt
\renewcommand{\arraystretch}{1.5} % Default value: 1
\begin{tabular}{||c | c||} 
    \hline
    Classification & Example \\ [0.5ex] 
    \hline\hline
    \textbf{Start Label} &  $<$script$>$, $<$body$>$, $<$img \\ 
    \hline
    \textbf{End Label} & $</$script$>$, $</$body$>$ \\
    \hline
    \textbf{Windows Event} & onerror=, onload=, onblur=, oncut= \\
    \hline
    \textbf{Function Name} & alert(, String.fromCharCode( \\
    \hline
    \textbf{Script URL} & javascript:, vbscript: \\ 
    \hline
    \textbf{Other} & $>$, ), \# \\ [1ex] 
    \hline
\end{tabular}
\endgroup
\caption{\label{tok:tab}DeepXSS Tokens.}
\end{center}
\end{table}

Once the URLs have been tokenized, they use CBOW to perform word embedding on the token strings \cite{fang2018deepxss}. They do this to extract the semantics of the tokens and provide more features to the LSTM \cite{fang2018deepxss}. They do not specify the numbder of dimensions their word vectors have nor the number of epochs used while training the CBOW model; CBOW is, of course, sensitive to both \cite{mikolov2013efficient}.

Once the word vectors are trained, the LSTM can be trained by feeding it sequences of word vectors representing URLs \cite{fang2018deepxss}. 